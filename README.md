# Activation-Functions

This Jupyter Notebook demonstrates the use of activation functions in neural networks. Activation functions are mathematical functions that are used to introduce non-linearity into the output of a neural network. They are applied to the output of each neuron in the network to determine whether the neuron should be activated or not.

The notebook defines several activation functions, including the sigmoid function, the ReLU function, and the tanh function. It then demonstrates the use of these functions in a simple neural network.
